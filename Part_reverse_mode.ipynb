{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3bbdcd",
   "metadata": {},
   "source": [
    "# Automatic differentiation: Reverse mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d03492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U \"jax[cpu]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e92a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, Math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cade36c",
   "metadata": {},
   "source": [
    "Lets use our previously used function:\n",
    "\n",
    "\\begin{gather*}\n",
    "f(x_1, x_2) = exp(x_1)-x_1 \\cdot x_2+cos(x_2)\n",
    "\\end{gather*}\n",
    "\n",
    "And do reverse and forward mode for AD\n",
    "\n",
    "In the following $x_1$ and $x_2$ will always have the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfd2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 2.0\n",
    "x2 = 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3f1f0",
   "metadata": {},
   "source": [
    "Therefore our function result is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd63eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2645875219329614\n"
     ]
    }
   ],
   "source": [
    "def f(x1, x2):\n",
    "    v1 = np.exp(x1)\n",
    "    v2 = x1*x2\n",
    "    v3 = np.cos(x2)\n",
    "    v4 = v1 - v2\n",
    "    v5 = v3 + v4\n",
    "    y = v5\n",
    "    return y\n",
    "\n",
    "print(f(x1,x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca43f0",
   "metadata": {},
   "source": [
    "## 1. With transverse jacobian\n",
    "For each of the derivative steps it helps to look at an example computational tree with reverse mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9649d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_rev(x1,dx1,deriv_child):\n",
    "    dx1 += deriv_child * np.exp(x1)\n",
    "    return dx1\n",
    "\n",
    "def mul_rev(x1,x2,dx1,dx2,deriv_child):\n",
    "    dx2 += deriv_child * x1\n",
    "    dx1 += deriv_child * x2\n",
    "    return dx1,dx2\n",
    "\n",
    "def dif_rev(x1,x2,dx1,dx2,deriv_child):\n",
    "    dx1 += deriv_child * 1\n",
    "    dx2 += deriv_child * (-1)\n",
    "    return dx1, dx2\n",
    "\n",
    "def cos_rev(x1,dx1,deriv_child):\n",
    "    dx1 += deriv_child * (-np.sin(x1))\n",
    "    return dx1\n",
    "\n",
    "def sum_rev(x1,x2,dx1,dx2,deriv_child):\n",
    "    dx1 += deriv_child * 1\n",
    "    dx2 += deriv_child * 1\n",
    "    return dx1,dx2\n",
    "\n",
    "\n",
    "def function_rev(x1, x2, dy):\n",
    "    \n",
    "    #run forward\n",
    "    v1 = np.exp(x1)\n",
    "    v2 = x1 * x2\n",
    "    v3 = np.cos(x2)\n",
    "    v4 = v1 - v2\n",
    "    v5 = v3 + v4\n",
    "    y = v5\n",
    "\n",
    "\n",
    "    #zero gradients \n",
    "    dx1 = 0\n",
    "    dx2 = 0\n",
    "    dv1 = 0\n",
    "    dv2 = 0\n",
    "    dv3 = 0\n",
    "    dv4 = 0\n",
    "    \n",
    "    #run backward\n",
    "    dv3,dv4  = sum_rev(v3, v4, dv3, dv4, dy)\n",
    "    dv1,dv2  = dif_rev(v1, v2, dv1, dv2, dv4)\n",
    "    dx2  = cos_rev(x2, dx2, dv3)\n",
    "    dx1,dx2 = mul_rev(x1,x2, dx1, dx2, dv2)\n",
    "    dx1  = exp_rev(x1, dx1, dv1)\n",
    "    \n",
    "    return y,[dx1,dx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "215fd992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.2645875219329614, [3.3890560989306504, -1.2431975046920718])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_rev(x1,x2,1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e5842",
   "metadata": {},
   "source": [
    "## 2. With Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f23f5291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install jax -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5d98720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b2faeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function uing jax numpy library\n",
    "def f_jax(x1, x2):\n",
    "    return jnp.exp(x1) - x1*x2 + jnp.cos(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ad4bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for first input position: 3.3890562\n",
      "Gradient for second input position: -1.2431974\n"
     ]
    }
   ],
   "source": [
    "# backward\n",
    "\n",
    "# define with argnum that gradient is derived for first input position\n",
    "print('Gradient for first input position:', jax.grad(f_jax, argnums=0)(x1, x2)) \n",
    "\n",
    "# define with argnum that gradient is derived for second input position\n",
    "print('Gradient for second input position:', jax.grad(f_jax, argnums=1)(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee82a1",
   "metadata": {},
   "source": [
    "## 3. With PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b6d1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8fb535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef14c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch can only use torch tensors as function input\n",
    "x1_t = torch.tensor([x1], requires_grad=True)\n",
    "x2_t = torch.tensor([x2], requires_grad=True)\n",
    "\n",
    "# define function\n",
    "def f_pt(x1_t, x2_t):\n",
    "\n",
    "    v1 = torch.exp(x1_t)\n",
    "    v2 = torch.matmul(x1_t, x2_t)\n",
    "    v3 = torch.cos(x2_t)\n",
    "    v4 = torch.sub(v1, v2)\n",
    "    v5 = torch.add(v3, v4)\n",
    "    y = v5\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "447d0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply reverse mode, we don't need to specify for which input position; it assigns the object variable\n",
    "torch.autograd.backward([f_pt(x1_t, x2_t)], inputs = [x1_t, x2_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b934c77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.3891])\n",
      "tensor([-1.2432])\n"
     ]
    }
   ],
   "source": [
    "# gradient is derived for first input position; assigns the variable\n",
    "print(x1_t.grad)\n",
    "\n",
    "# gradient is derived for second input position\n",
    "print(x2_t.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223ca79",
   "metadata": {},
   "source": [
    "## 4. With TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4467473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99eb6c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07d1adfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75 ms ± 374 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2.300999879837036 3.3890562 -1.2431974\n"
     ]
    }
   ],
   "source": [
    "# tensorflow functions only work with tensorflow tensors\n",
    "x1_tf = tf.Variable(x1)\n",
    "x2_tf = tf.Variable(x2)\n",
    "\n",
    "# define function with tensorflow mathematical differentiation\n",
    "def f_tf(x1_tf, x2_tf):\n",
    "    v1 = tf.math.exp(x1_tf)\n",
    "    v2 = tf.math.multiply(x1_tf, x2_tf)\n",
    "    v3 = tf.math.cos(x2_tf)\n",
    "    v4 = tf.math.subtract(v1, v2)\n",
    "    v5 = tf.math.add(v3, v4)\n",
    "    y = v5\n",
    "    return y\n",
    "\n",
    "\n",
    "def train_tf(x1_tf, x2_tf):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # forward pass\n",
    "        y = f_tf(x1_tf, x2_tf)\n",
    "        \n",
    "    # compute reverse AD\n",
    "    gradients = tape.gradient(y, [x1_tf, x2_tf])\n",
    "    return gradients\n",
    "\n",
    "t1 = time.time()\n",
    "gradients = train_tf(x1_tf, x2_tf)\n",
    "%timeit train_tf(x1_tf, x2_tf)\n",
    "t2 = time.time()\n",
    "print(t2-t1, gradients[0].numpy(), gradients[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d71451",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "print derivative of function for all different approaches and how long it took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a083592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Gradient via Jacobian-vector-product:\n",
      "f(2.0, 4.0)= -1.265 with dx1= 3.389 and dx2= -1.243\n",
      "10.5 µs ± 3.32 µs per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "\n",
      "\n",
      "2. Gradient via Jax\n",
      "f(2.0, 4.0)= -1.2650001 with dx1= 3.3890002 and dx2= -1.243\n",
      "7 ms ± 349 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "lets try with jit\n",
      "2.72 ms ± 65.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "4 ms ± 960 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "\n",
      "3. Gradient via PyTorch\n",
      "f(2.0, 4.0)= tensor([-1.2646], grad_fn=<AddBackward0>) with dx1= tensor([3.3891]) and dx2= tensor([-1.2432])\n",
      "330 µs ± 39 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "\n",
      "\n",
      "4. Gradient via TensorFlow\n",
      "f(2.0, 4.0)= -1.2645874 with dx1= 3.3890562 and dx2= -1.2431974\n",
      "2.8 ms ± 501 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "print('1. Gradient via Jacobian-vector-product:')\n",
    "f_rev, [dx1, dx2] = function_rev(x1,x2,1.0)\n",
    "print(f'f({x1}, {x2})=', round(f_rev, 3), 'with dx1=', round(dx1,3), 'and dx2=', round(dx2,3))\n",
    "%timeit function_rev(x1,x2,1.0)\n",
    "\n",
    "print('\\n')\n",
    "print('2. Gradient via Jax')\n",
    "f_jx = f_jax(x1, x2)\n",
    "dx1, dx2 = jax.grad(f_jax, argnums=0)(x1, x2), jax.grad(f_jax, argnums=1)(x1, x2)\n",
    "print(f'f({x1}, {x2})=', round(f_jx, 3), 'with dx1=', round(dx1,3), 'and dx2=', round(dx2,3))\n",
    "%timeit jax.grad(f_jax, argnums=0)(x1, x2)\n",
    "\n",
    "print('lets try with jit')\n",
    "jit_f_jx = jax.jit(f_jax)\n",
    "%timeit jax.grad(jit_f_jx, argnums=0)(x1, x2)\n",
    "%timeit jax.grad(jit_f_jx, argnums=0)(x1, x2).block_until_ready()\n",
    "\n",
    "print('\\n')\n",
    "print('3. Gradient via PyTorch')\n",
    "x1_t, x2_t = torch.tensor([x1], requires_grad=True), torch.tensor([x2], requires_grad=True)\n",
    "f_pyt = f_pt(x1_t, x2_t)\n",
    "torch.autograd.backward([f_pt(x1_t, x2_t)], inputs = [x1_t, x2_t])\n",
    "dx1, dx2 = x1_t.grad, x2_t.grad\n",
    "print(f'f({x1}, {x2})=', f_pyt, 'with dx1=', dx1, 'and dx2=', dx2)\n",
    "%timeit torch.autograd.backward([f_pt(x1_t, x2_t)], inputs = [x1_t, x2_t])\n",
    "\n",
    "print('\\n')\n",
    "print('4. Gradient via TensorFlow')\n",
    "x1_tf, x2_tf = tf.Variable(x1), tf.Variable(x2)\n",
    "f_tfw = f_tf(x1_tf, x2_tf)\n",
    "gradients = train_tf(x1_tf, x2_tf)\n",
    "print(f'f({x1}, {x2})=', f_tfw.numpy(), 'with dx1=', gradients[0].numpy(), 'and dx2=', gradients[1].numpy())\n",
    "%timeit train_tf(x1_tf, x2_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450cf7d",
   "metadata": {},
   "source": [
    "## Check difference between tensorflow with and without XLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7da4fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train normal tensorflow\n",
    "x1_tf, x2_tf = tf.Variable(x1), tf.Variable(x2)\n",
    "\n",
    "t1 = time.time()\n",
    "gradients = train_tf(x1_tf, x2_tf)\n",
    "t2 = time.time()\n",
    "\n",
    "t_tf = t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c95a159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with tensorflow and jit\n",
    "\n",
    "t1 = time.time()\n",
    "@tf.function(jit_compile=True)\n",
    "def train_jit(x1_tf, x2_tf):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # forward pass\n",
    "        y = f_tf(x1_tf, x2_tf)\n",
    "    gradients = tape.gradient(y, [x1_tf, x2_tf])\n",
    "t2 = time.time()\n",
    "t_tf_jit = t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36b5dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed for tensorflow: 0.004996061325073242\n",
      "Time needed for tensorflow with jit: 0.007998228073120117\n"
     ]
    }
   ],
   "source": [
    "print('Time needed for tensorflow:', t_tf)\n",
    "print('Time needed for tensorflow with jit:', t_tf_jit) # using XLA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2325cc66",
   "metadata": {},
   "source": [
    "# Forward mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e2979",
   "metadata": {},
   "source": [
    "## 1. With Jacobian\n",
    "For a better understanding look at the computation steps of the forward mode using a computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebd6dd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1.2645875219329614, 3.3890560989306504)\n",
      "(-1.2645875219329614, -1.2431975046920718)\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "def mul_forward(x1,dx1,x2,dx2):\n",
    "    y  = x1*x2\n",
    "    dy = x1*dx2 + x2*dx1\n",
    "    return y, dy\n",
    "\n",
    "def sum_forward(x1,dx1,x2,dx2):\n",
    "    return x1+x2, dx1 + dx2\n",
    "\n",
    "def dif_forward(x1,dx1,x2,dx2):\n",
    "    return x1-x2, dx1 - dx2\n",
    "\n",
    "def exp_forward(x1,dx1):\n",
    "    return np.exp(x1), dx1 * np.exp(x1)\n",
    "\n",
    "def cos_forward(x2,dx2):\n",
    "    return np.cos(x2), - dx2 * np.sin(x2)\n",
    "\n",
    "def function_forward(x,dx):\n",
    "    x1,x2 = x\n",
    "    dx1,dx2 = dx\n",
    "    v1, dv1 = exp_forward(x1,dx1)\n",
    "    v2,dv2 = mul_forward(x1,dx1,x2,dx2)\n",
    "    v3, dv3 = cos_forward(x2,dx2)\n",
    "    v4, dv4 = dif_forward(v1,dv1,v2,dv2)\n",
    "    v5, dv5 = sum_forward(v3,dv3,v4,dv4)\n",
    "    y, dy = v5, dv5\n",
    "    return y, dy\n",
    "\n",
    "print(function_forward([x1,x2],[1,0]))\n",
    "print(function_forward([x1,x2],[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52872577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.75 µs ± 1.43 µs per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit function_forward([x1,x2],[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b883fa8",
   "metadata": {},
   "source": [
    "## 2. With Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f94bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y= -1.2645874 , dy= 3.3890562\n",
      "y= -1.2645874 , dy= -1.2431974\n",
      "5.73 ms ± 866 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "\n",
    "y, f_jvp = jax.jvp(f_jax, (x1, x2,), (1.0, 0.0,))\n",
    "print('y=', y, ', dy=', f_jvp)\n",
    "\n",
    "y, f_jvp = jax.jvp(f_jax, (x1, x2,), (0.0, 1.0,))\n",
    "print('y=', y, ', dy=', f_jvp)\n",
    "\n",
    "%timeit jax.jvp(f_jax, (x1, x2,), (1.0, 0.0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a70f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
